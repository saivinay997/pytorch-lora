{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular value decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0797,  0.5545,  0.8058, -0.7140, -0.1518,  1.0773,  2.3690,  0.8486,\n",
      "         -1.1825, -3.2632],\n",
      "        [-0.3303,  0.2283,  0.4145, -0.1924, -0.0215,  0.3276,  0.7926,  0.2233,\n",
      "         -0.3422, -0.9614],\n",
      "        [-0.5256,  0.9864,  2.4447, -0.0290,  0.2305,  0.5000,  1.9831, -0.0311,\n",
      "         -0.3369, -1.1376],\n",
      "        [ 0.7900, -1.1336, -2.6746,  0.1988, -0.1982, -0.7634, -2.5763, -0.1696,\n",
      "          0.6227,  1.9294],\n",
      "        [ 0.1258,  0.1458,  0.5090,  0.1768,  0.1071, -0.1327, -0.0323, -0.2294,\n",
      "          0.2079,  0.5128],\n",
      "        [ 0.7697,  0.0050,  0.5725,  0.6870,  0.2783, -0.7818, -1.2253, -0.8533,\n",
      "          0.9765,  2.5786],\n",
      "        [ 1.4157, -0.7814, -1.2121,  0.9120,  0.1760, -1.4108, -3.1692, -1.0791,\n",
      "          1.5325,  4.2447],\n",
      "        [-0.0119,  0.6050,  1.7245,  0.2584,  0.2528, -0.0086,  0.7198, -0.3620,\n",
      "          0.1865,  0.3410],\n",
      "        [ 1.0485, -0.6394, -1.0715,  0.6485,  0.1046, -1.0427, -2.4174, -0.7615,\n",
      "          1.1147,  3.1054],\n",
      "        [ 0.9088,  0.1936,  1.2136,  0.8946,  0.4084, -0.9295, -1.2294, -1.1239,\n",
      "          1.2155,  3.1628]]) torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "## Generate a rank deficient matrix\n",
    "\n",
    "d, k = 10, 10\n",
    "\n",
    "# this way we can generate a rank deficient matrix\n",
    "W_rank = 2\n",
    "W = torch.randn(d, W_rank) @ torch.randn(W_rank, k)\n",
    "print(W, W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of W: 2\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the rank of the matrix W\n",
    "W_rank = np.linalg.matrix_rank(W)\n",
    "print(f\"Rank of W: {W_rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of B: torch.Size([10, 2])\n",
      "Shape of A: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "## Perform SVD on W (W = UxSxV^T)\n",
    "U, S, V = torch.svd(W)\n",
    "\n",
    "# For rank-r factorization, we can truncate the SVD to the first r singular values\n",
    "U_r = U[:,:W_rank]\n",
    "S_r = torch.diag(S[:W_rank])\n",
    "V_r = V[:,:W_rank].t() # transpose V_r to get the right dimensions\n",
    "\n",
    "# Compute B = U_r x S_r and A = V_r\n",
    "B = U_r @ S_r\n",
    "A = V_r\n",
    "print(f\"Shape of B: {B.shape}\")\n",
    "print(f\"Shape of A: {A.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output using W: tensor([-4.2808, -1.2647,  2.9707, -0.9784,  0.9193,  3.5211,  5.3049,  5.5870,\n",
      "         1.8145,  4.7644])\n",
      "Output using BA: tensor([-4.2808, -1.2647,  2.9707, -0.9784,  0.9193,  3.5211,  5.3049,  5.5870,\n",
      "         1.8145,  4.7644])\n",
      "Difference between the two outputs: 4.846704541705549e-06\n"
     ]
    }
   ],
   "source": [
    "## Given the same input, check the output using the original W matrix and the matrices resulting from the decomposition\n",
    "\n",
    "# Generate random bias and input\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(d)\n",
    "\n",
    "# Compute y = Wx + bias\n",
    "output_W = W @ x + bias\n",
    "\n",
    "# Compute y' = (B*A)x + bias\n",
    "output_BA = B @ (A @ x) + bias\n",
    "\n",
    "# Check if the outputs are the same\n",
    "print(f\"Output using W: {output_W}\")\n",
    "print(f\"Output using BA: {output_BA}\")\n",
    "\n",
    "# Find the differences between the two outputs\n",
    "diff = torch.norm(output_W - output_BA)\n",
    "print(f\"Difference between the two outputs: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params in W: 100\n",
      "Total params in B and A: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Total params in W:\", W.numel())\n",
    "print(\"Total params in B and A:\", B.numel() + A.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
